{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "218016f8-7692-4303-abe4-8b163d20d9f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mounting s3 bucket and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c80d137-244f-4489-95c3-8c9b0f90a90a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pyspark functions\n",
    "from pyspark.sql.functions import *\n",
    "# URL processing\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c82b0d3-3699-410a-809f-3764ba476f92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the Delta table\n",
    "delta_table_path = \"dbfs:/user/hive/warehouse/authentication_credentials\"\n",
    "\n",
    "# Read the Delta table to a Spark DataFrame\n",
    "aws_keys_df = spark.read.format(\"delta\").load(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1558a28-8e0c-4364-9e23-b3f311e94c85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the AWS access key and secret key from the spark dataframe\n",
    "ACCESS_KEY = aws_keys_df.select('Access key ID').collect()[0]['Access key ID']\n",
    "SECRET_KEY = aws_keys_df.select('Secret access key').collect()[0]['Secret access key']\n",
    "# Encode the secrete key\n",
    "ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28383fcf-d867-4cba-842e-43be16162a93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# AWS S3 bucket name\n",
    "AWS_S3_BUCKET = \"user-129fb6ae3c55-bucket\"\n",
    "# Mount name for the bucket\n",
    "MOUNT_NAME = \"/mnt/user-129fb6ae3c55-bucket\"\n",
    "# Source url\n",
    "SOURCE_URL = \"s3n://{0}:{1}@{2}\".format(ACCESS_KEY, ENCODED_SECRET_KEY, AWS_S3_BUCKET)\n",
    "# Mount the drive\n",
    "dbutils.fs.mount(SOURCE_URL, MOUNT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36594589-fcab-4e51-9adf-c85b1fb140c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# list the topics stored on the mounted S3 bucket\n",
    "display(dbutils.fs.ls(\"s3n://user-129fb6ae3c55-bucket/topics\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8930a4d9-a945-42bc-aa4a-cefd2b766981",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/* Disable format checks during the reading of Delta tables */\n",
    "SET spark.databricks.delta.formatCheck.enabled=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bf68a69-0575-4111-b316-418416cf8418",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File locations and types\n",
    "pin_file_location = \"s3n://user-129fb6ae3c55-bucket/topics/129fb6ae3c55.pin//partition=0/*.json\"\n",
    "geo_file_location = \"s3n://user-129fb6ae3c55-bucket/topics/129fb6ae3c55.geo//partition=0/*.json\"\n",
    "user_file_location = \"s3n://user-129fb6ae3c55-bucket/topics/129fb6ae3c55.user//partition=0/*.json\"\n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schemas\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 buckets\n",
    "df_pin = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(pin_file_location)\n",
    "df_geo = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(geo_file_location)\n",
    "df_user = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(user_file_location)\n",
    "\n",
    "# Display Spark dataframes\n",
    "df_pin.limit(10).display()\n",
    "df_geo.limit(10).display()\n",
    "df_user.limit(10).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f078da7-95d0-4db1-8160-53805e90a8f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Cleaning df_pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f2d6974-fd94-4b16-aee1-7052d9127582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining function to replace entries that or empty or contain no relevant data with None\n",
    "def change_to_None(df, column, entry_value):\n",
    "    clean_df = df.withColumn(column, when(col(column).like(entry_value), None).otherwise(col(column)))\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d3998cc-06d6-4576-a9ca-7286432bd69c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of values to replace with None\n",
    "replace_with_None = {\n",
    "    \"description\": \"No description available%\",\n",
    "    \"follower_count\": \"User Info Error\",\n",
    "    \"image_src\": \"Image src error.\",\n",
    "    \"poster_name\": \"User Info Error\",\n",
    "    \"tag_list\": \"N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e\",\n",
    "    \"title\": \"No Title Data Available\"\n",
    "}\n",
    "\n",
    "for key, value in replace_with_None.items():\n",
    "    df_pin = change_to_None(df_pin, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d118df0f-39d5-405b-b9e1-d87aa65396ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform the necessary transformations on the follower_count to ensure every entry is a number. Make sure the data type of this column is an int\n",
    "df_pin = df_pin.withColumn(\"follower_count\", regexp_replace(\"follower_count\", \"k\", \"000\"))\n",
    "df_pin = df_pin.withColumn(\"follower_count\", regexp_replace(\"follower_count\", \"M\", \"000000\"))\n",
    "\n",
    "df_pin = df_pin.withColumn(\"follower_count\", col(\"follower_count\").cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46d5ef1d-d7f4-4f69-97c0-8644dd059109",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean the data in the save_location column to include only the save location path\n",
    "df_pin = df_pin.withColumn(\"save_location\", regexp_replace(\"save_location\", \"Local save in \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1887329-5020-4f36-b1f2-4dbe1140d466",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Renaming \"index\" column\n",
    "df_pin = df_pin.withColumnRenamed(\"index\", \"ind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02b89db2-d292-40c5-a7c9-c267143d3e32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reordering dataframe columns to desired order\n",
    "df_pin = df_pin.select(\n",
    "    \"ind\",\n",
    "    \"unique_id\",\n",
    "    \"title\",\n",
    "    \"description\",\n",
    "    \"follower_count\",\n",
    "    \"poster_name\",\n",
    "    \"tag_list\",\n",
    "    \"is_image_or_video\",\n",
    "    \"image_src\",\n",
    "    \"save_location\",\n",
    "    \"category\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e45fd26e-9352-46ec-9be1-108d72c537ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Cleaning df_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65f77b0f-30ac-44b5-a4aa-868e897fcd00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column coordinates that contains an array based on the latitude and longitude columns\n",
    "df_geo = df_geo.withColumn(\"coordinates\", array(\"latitude\", \"longitude\"))\n",
    "# Dropping the latitude and longitude columns\n",
    "df_geo = df_geo.drop(\"latitude\", \"longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a213c3b0-9764-4d82-b541-9b11627fba13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the timestamp column from a string to a timestamp data type\n",
    "df_geo = df_geo.withColumn(\"timestamp\", to_timestamp(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c69edc9-9015-4396-84a9-cf11226644a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reordering dataframe columns to desired orders\n",
    "df_geo = df_geo.select(\n",
    "    \"ind\",\n",
    "    \"country\",\n",
    "    \"coordinates\",\n",
    "    \"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8546d2a-257b-4aa1-9c44-109ad576d070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Cleaning df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac5a589a-00b1-465f-bdd9-9bfbad399ef8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column user_name that concatenates the information found in the first_name and last_name columns\n",
    "df_user = df_user.withColumn(\"user_name\", concat(\"first_name\",lit(\" \"), \"last_name\"))\n",
    "# Dropping first_name and last_name columns\n",
    "df_user = df_user.drop(\"first_name\", \"last_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e85cdd77-6386-4273-aa1e-694cb14ca938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the date_joined column from a string to a timestamp data type\n",
    "df_user = df_user.withColumn(\"date_joined\", to_timestamp(\"date_joined\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a83a7d6c-ce22-412e-a443-c766cfbff511",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reordering dataframe columns to desired order\n",
    "df_user = df_user.select(\n",
    "    \"ind\",\n",
    "    \"user_name\",\n",
    "    \"age\",\n",
    "    \"date_joined\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae1f980f-6444-4aa6-9119-5370fa35d557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Querying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4649f55e-b4a9-447c-bb7f-dc788a0e5c90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "df_pin_geo = df_pin.join(df_geo, df_pin.ind == df_geo.ind)\n",
    "# create join of df_pin and df_user and a temporary view to run SQL query to create age group column\n",
    "df_pin.join(df_user, df_pin.ind == df_user.ind).createOrReplaceTempView(\"category_age\")\n",
    "age_groups = spark.sql(\n",
    "    \"SELECT CASE \\\n",
    "        WHEN age between 18 and 24 then '18-24' \\\n",
    "        WHEN age between 25 and 35 then '25-35' \\\n",
    "        WHEN age between 36 and 50 then '36-50' \\\n",
    "        WHEN age > 50 then '50+' \\\n",
    "        END as age_group, * FROM category_age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71f415a7-3230-44d5-bcc8-51596bfb2556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Find the most popular category in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7e9ae6e-67fb-4640-a683-e22479050041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# order by category_count column and partition by country column\n",
    "window_popular_category = Window.partitionBy(\"country\").orderBy(col(\"category_count\").desc())\n",
    "# use aggregation function with df_pin_geo dataframe and window function to find the most popular category in each country\n",
    "df_pin_geo.groupBy(\"country\", \"category\") \\\n",
    ".agg(count(\"category\").alias(\"category_count\")) \\\n",
    ".withColumn(\"ranking\", row_number().over(window_popular_category)) \\\n",
    ".filter(col(\"ranking\") == 1).drop(\"ranking\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8588c8d5-db81-4a89-8c9a-852bced8fc51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Find which was the most popular category each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b13357f-e76c-49e0-9164-fefab7ed15ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# order by category_count column and partition by post_year column\n",
    "window_popular_category_year = Window.partitionBy(\"post_year\").orderBy(col(\"category_count\").desc())\n",
    "# use aggregation function with df_pin_geo dataframe and window function to find the most popular category in each year\n",
    "df_pin_geo.withColumn(\"post_year\", year(\"timestamp\")) \\\n",
    ".filter(col(\"post_year\") >= 2018).filter(col(\"post_year\") <= 2022) \\\n",
    ".groupBy(\"post_year\", \"category\").agg(count(\"category\").alias(\"category_count\")) \\\n",
    ".withColumn(\"ranking\", row_number().over(window_popular_category_year)) \\\n",
    ".filter(col(\"ranking\") == 1).drop(\"ranking\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0fb2d92-1f44-458a-8a9d-1cd9ce94f4ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Find the user with the most followers in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f0eb56c-320d-479d-a788-782fa59da909",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# order by follower_count column and partition by country column\n",
    "window_followers_by_country = Window.partitionBy(\"country\").orderBy(col(\"follower_count\").desc())\n",
    "# use df_pin_geo dataframe and window function to find the user with the most followers in each country\n",
    "max_followers = df_pin_geo.withColumn(\"ranking\", row_number().over(window_followers_by_country)) \\\n",
    "    .filter(col(\"ranking\") == 1).select(\"country\", \"poster_name\", \"follower_count\")\n",
    "\n",
    "max_followers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50c6ae63-d6f7-49d0-bc38-53bffb44c056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Find the country with the user with most followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93a01e7a-02ef-4fb9-979d-2f0f8fc1e037",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# find max followers from max_followers dataframe\n",
    "max_user_followers = max_followers.select(max(\"follower_count\")).collect()[0][0]\n",
    "# use top result of max_followers dataframe to find the country with the user with the most followers\n",
    "country_max_followers = max_followers.select(\"*\").where(col(\"follower_count\") == max_user_followers)\n",
    "country_max_followers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2235cd78-1b54-4b16-89b7-550b16708950",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Find the most popular category for different age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75336c47-d23d-4a1d-873c-39cd9c721045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# order by category_count column and partition by age_group column\n",
    "window_popular_category_by_age = Window.partitionBy(\"age_group\").orderBy(col(\"category_count\").desc())\n",
    "# from age_groups use aggregation function to find the most popular category by age group\n",
    "age_groups.groupBy(\"age_group\", \"category\").agg(count(\"category\").alias(\"category_count\")) \\\n",
    ".withColumn(\"rank\", row_number().over(window_popular_category_by_age)) \\\n",
    ".filter(col(\"rank\") == 1).drop(\"rank\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bf6c347-8e9a-4359-9212-e3d3792aaf22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Find the median follower count for different age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "223f49a2-7eed-493a-b02a-a0cdc2cc148c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from age_groups use aggregation function to find the median followers ordered by age group\n",
    "age_groups.select(\"user_name\", \"date_joined\", \"age_group\", \"follower_count\") \\\n",
    ".distinct().groupBy(\"age_group\").agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\")) \\\n",
    ".orderBy(\"age_group\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7c1eb6c-cb16-4c2d-bd5f-2129874d6bd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Find how many users joined each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6b5773a-abc0-46d9-9873-9a0974c390f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# user user_df and aggregation function to find how many users joined in each year\n",
    "df_user.withColumn(\"post_year\", year(\"date_joined\")).drop(\"ind\").distinct() \\\n",
    ".filter(col(\"post_year\") >= 2015).filter(col(\"post_year\") <= 2020) \\\n",
    ".groupBy(\"post_year\").agg(count(\"user_name\").alias(\"number_users_joined\")) \\\n",
    ".orderBy(\"post_year\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e058356c-4625-444e-a9ad-cc36dfb82b35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Find the median follower count of users based on their joining year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3410f74c-4f47-4b6b-a83e-0ef7d6d82dfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# use age_groups and aggregation function to find the median followers based on their joining year\n",
    "age_groups.select(\"user_name\", \"date_joined\", \"follower_count\") \\\n",
    ".distinct().withColumn(\"post_year\", year(\"date_joined\")) \\\n",
    ".groupBy(\"post_year\").agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\")) \\\n",
    ".orderBy(\"post_year\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3ba198a-c1e1-42d8-9126-a9b67a29c59d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Find the median follower count of users based on their joining year and age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c1c51fe-ba3e-4ae7-81cc-3292b6c43a3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# use age_groups and aggregation function to find the median followers of users based on their joining year and age group\n",
    "age_groups.select(\"user_name\", \"age_group\", \"date_joined\", \"follower_count\") \\\n",
    ".distinct().withColumn(\"post_year\", year(\"date_joined\")) \\\n",
    ".groupBy(\"post_year\", \"age_group\").agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\")) \\\n",
    ".orderBy(\"post_year\", \"age_group\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f0e2e1-484b-4e72-b694-3065ae0ed433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Unmount s3 bucket\n",
    "dbutils.fs.unmount(\"/mnt/user-129fb6ae3c55-bucket\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1338703037918758,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "mount_s3_load_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
